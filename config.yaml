# Configuration for Unsafe Action Detection System

# Dataset Configuration
dataset:
  name: "folders"  # Options: "bdd100k", "covla", "folders" (use only additional_folders)
  
  # BDD100K Configuration (when name: "bdd100k")
  root_dir: "datasets/bdd100k"
  video_dir: "datasets/bdd100k/videos"
  annotations_file: "datasets/bdd100k/annotations.json"
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  
  # CoVLA Configuration (when name: "covla")
  hf_dataset_name: "turing-motors/CoVLA-Dataset"  # Hugging Face dataset name
  cache_dir: "data/covla_cache"  # Local cache directory
  use_mini: false  # Set to true for testing with CoVLA-Dataset-Mini
  
  # Additional folders to include in training
  # Videos from these folders will be combined with the main dataset
  additional_folders:
    - path: "datasets/CharadesEgo_v1/videos"
      default_label: 0  # Label for all videos (0 = safe, 1+ = unsafe)
      recursive: true   # Search subdirectories recursively
    - path: "datasets/missing_files_v1-2_test/videos"
      default_label: 0
      recursive: true
  
# Unsafe Action Categories - PPE and Safety Violations
# These map to labels used in Label Studio annotations
unsafe_actions:
  0: "Safe"
  1: "No PPE - Missing Gloves"
  2: "No PPE - Missing Helmet"
  3: "No PPE - Missing Safety Glasses"
  4: "No PPE - Missing High Visibility Vest"
  5: "Other Violation"
  6: "Unsafe Behavior"
  7: "Near Miss"

# Jurisdiction and Industry-Specific Action Categories
jurisdiction_industry_actions:
  ontario_food_safety:
    - "no_hair_net"
    - "no_gloves"
    - "cross_contamination"
    - "improper_temperature_handling"
    - "improper_uniform"
  
  ontario_construction:
    - "no_hard_hat"
    - "no_safety_harness"
    - "unsafe_scaffolding"
    - "no_high_visibility_vest"
    - "improper_hard_hat"
  
  ontario_light_industry:
    - "no_safety_glasses"
    - "loose_clothing_near_machinery"
    - "improper_lifting"
    - "improper_eye_protection"
    - "unsecured_hair"
    - "jewelry_near_machinery"
    - "overloading"
  
  generic_general:
    - "unsafe_behavior"
    - "slip_trip_hazard"
    - "blocked_emergency_exit"
    - "fire_hazard"

# Model Configuration
model:
  architecture: "video_action_detector"  # Options: video_action_detector, lstm, c3d
  backbone: "resnet18"  # Use resnet18 for faster training (resnet50 for better accuracy)
  num_classes: 8  # Number of classes: Safe + 7 violation types
  num_frames: 16  # Number of frames to process at once (reduce to 8 if GPU memory issues)
  frame_interval: 2  # Sample every N frames
  input_size: [224, 224]  # Frame resolution
  dropout: 0.5
  pretrained: true

# Training Configuration
# RECOMMENDED: Install PyTorch with CUDA to use your RTX 4060 GPU (10-30x faster!)
# Run: pip uninstall torch torchvision && pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
training:
  # GPU Settings (RTX 4060 with 4GB VRAM) - Uncomment when CUDA is installed
  batch_size: 4          # Increase to 4-6 for GPU (currently 2 for CPU)
  num_epochs: 30         # Increase to 30-50 for GPU (currently 5 for quick CPU test)
  num_workers: 4         # Increase to 4-6 for GPU (currently 0 for CPU)
  device: "cuda"         # Use "cuda" for GPU, "cpu" for CPU-only
  
  # CPU Settings (if not using GPU) - Use these values:
  # batch_size: 2
  # num_epochs: 5-10
  # num_workers: 0
  # device: "cpu"
  
  # Optimizer settings
  learning_rate: 0.001
  weight_decay: 0.0001
  optimizer: "adam"  # Options: adam, sgd, adamw
  scheduler: "cosine"  # Options: cosine, step, plateau
  warmup_epochs: 5
  gradient_clip: 1.0
  
# Data Augmentation
augmentation:
  random_crop: true
  horizontal_flip: 0.5
  color_jitter: 0.2
  rotation: 10
  temporal_crop: true
  
# Real-time Inference
inference:
  confidence_threshold: 0.7  # Minimum confidence to trigger alert
  temporal_smoothing: true
  smoothing_window: 5  # Number of frames for temporal smoothing
  alert_cooldown: 3.0  # Seconds between alerts for same action
  video_buffer_size: 32  # Frames to keep in buffer
  fps: 30

# Alert/Notification System
alerts:
  enabled: true
  methods: ["console", "file", "webhook"]  # notification methods
  log_file: "logs/alerts.log"
  webhook_url: null  # Set to your webhook URL for notifications
  save_clips: true  # Save video clips of unsafe actions
  clip_duration: 5  # Seconds of video to save around detection
  clips_dir: "output/alert_clips"

# Logging
logging:
  level: "INFO"
  save_dir: "logs"
  tensorboard: true
  tensorboard_dir: "runs"
  save_frequency: 5  # Save model every N epochs

# Checkpointing
checkpointing:
  save_dir: "checkpoints"
  save_best_only: false
  monitor: "val_accuracy"

